
## Week 6: gradient descent in practice cont.

### Update:
After speaking to professor Bernardo, I realized the implementation requires a separate training loop. The tape only performs one pass over the function. I assumed it would do the training process by itself. 

### The plan:
I need to make a training loop for the x to be updated. I noticed the professor referenced a section in the TF help pages about such loops; hence, I will look into this section for guidance. The TF help page contained information on training loops using Keras, or a more primitive method. I chose to get my hands dirty with the primitive method. After reading through it I’ve identified some key components needed. I will need a learning rate which will update our x value on each pass, a loss function – in our case it's the previously mentioned polynomial, and a current[] and last[] list for keeping track of our x value, on the respective passes. I will stop the loop once it has passed a maximum iteration allowed, or once the values of the current pass and the last pass are < 1e-4 of each other.

### Implementation:
After making the adjustments mentioned above, I had a working loop; however, I encountered an issue with the values it was outputting. 
<img width="445" height="324" alt="image" src="https://github.com/user-attachments/assets/cf51dbb6-2c58-4b68-b92b-1694d188b894" />

The above image shows the initial values growing in very large steps, followed by nan values until the loop hit the max iterations. This meant the function was growing incorrectly. To debug this I addressed the extremely large steps it took in each pass. Considering the learning rate was responsible for shifting the x, and the polynomial can change fairly often and fast–I thought it would be best to lower the learning rate, for more fidelity over the function.

This produced the following output:

<img width="361" height="409" alt="image" src="https://github.com/user-attachments/assets/0b72433c-8592-42b7-bede-829d7d18f287" />
<img width="683" height="482" alt="image" src="https://github.com/user-attachments/assets/f67e6051-eaad-4f16-b7af-66f476e497bf" />

Here we see the function is correctly finding a local minima, but its hitting the max iterations rather than stopping when its close enough. So I changed the max iteration, this gave a better and final result:

<img width="363" height="267" alt="image" src="https://github.com/user-attachments/assets/6c6a7516-42fd-4b3c-a29b-0b9728b6fe50" />
<img width="635" height="472" alt="image" src="https://github.com/user-attachments/assets/0d3f2641-5b16-4b31-9246-7f210909919a" />



