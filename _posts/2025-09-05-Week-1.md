## Week 1: Researching existing datasets and methods.

  While learning how to play electronic drums, I started taking interest in the technology behind it. After understanding how the [current technology](https://github.com/corrados/edrumulus) works, I wanted to investigate a way to use modern AI/ML as a means of signal processing; furthermore, I needed to make my process replicable by others, and work on an embedded device; hence, I found it would be necessary to use TFLite and an edge AI tool suite for conversion (I will be using [ST’s](https://www.st.com/content/st_com/en/st-edge-ai-suite/tools.html)). 

The first place I looked was signal classification using CNNs. This approach is problematic. A large number of classes is needed to maintain fidelity of the drum hits. It's difficult to find a large enough dataset and keep training time low. That is something I would like to avoid. While investigating a different method, I came across a paper that used the same sensors for positional sensing instead.

[This](https://pmc.ncbi.nlm.nih.gov/articles/PMC11314976/) paper gave me the idea to investigate using positional sensing with multiple piezos. To implement this idea I need to figure out how to classify multiple sensor outputs across time. I’m going to discuss whether the methods in the paper are applicable to my project with professor Bernardo.

